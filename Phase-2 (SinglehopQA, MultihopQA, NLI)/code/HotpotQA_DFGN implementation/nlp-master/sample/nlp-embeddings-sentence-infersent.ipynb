{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2031\n",
      "Val: 226\n",
      "Test: 1502\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "train_raw_df = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test_raw_df = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(np.array(train_raw_df.data), train_raw_df.target, test_size=0.1)\n",
    "x_test = np.array(test_raw_df.data)\n",
    "y_test = test_raw_df.target\n",
    "\n",
    "# x_train = [x_train[:200] for x in x_train]\n",
    "\n",
    "print('Train:', len(x_train))\n",
    "print('Val:', len(x_val))\n",
    "print('Test:', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /data/jupyter/common into sys.path.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext  autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "def add_aion(curr_path=None):\n",
    "    if curr_path is None:\n",
    "        dir_path = os.getcwd()\n",
    "        target_path = os.path.dirname(dir_path)\n",
    "        if target_path not in sys.path:\n",
    "            print('Added %s into sys.path.' % (target_path))\n",
    "            sys.path.insert(0, target_path)\n",
    "            \n",
    "add_aion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dscoe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aion.embeddings.infersent import InferSentEmbeddings\n",
    "\n",
    "infer_sent_embs = InferSentEmbeddings(word_embeddings_dir='../model/text/stanford/glove/', verbose=20)\n",
    "infer_sent_embs.load_model(dest_dir='../model/text/facebook/infersent/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22119(/46170) words with w2v vectors\n",
      "Vocab size : 22119\n"
     ]
    }
   ],
   "source": [
    "infer_sent_embs.build_vocab(x_train, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jupyter/common/aion/embeddings/infersent_lib/models.py:222: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  sentences[stidx:stidx + bsize]), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "x_train_t = infer_sent_embs.encode(x_train, tokenize=True)\n",
    "x_test_t = infer_sent_embs.encode(x_test, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='newton-cg', max_iter=1000)\n",
    "model.fit(x_train_t, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:86.55%\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.76      0.80       319\n",
      "          1       0.86      0.95      0.91       389\n",
      "          2       0.95      0.79      0.86       396\n",
      "          3       0.82      0.94      0.87       398\n",
      "\n",
      "avg / total       0.87      0.87      0.86      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Accuracy:%.2f%%' % (accuracy_score(y_test, y_pred)*100))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
