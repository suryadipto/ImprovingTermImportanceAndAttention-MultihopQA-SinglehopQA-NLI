{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lemmatization](https://www.tell-a-tale.com/wp-content/uploads/2018/03/time-for-a-change-2015164_960_720_compressed-810x539.jpg)\n",
    "\n",
    "Source: https://www.tell-a-tale.com/unbox-idea-social-open-mic-tell-a-story-to-change-world/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "In English words (Other language as well), same word may have different form such as \"affected\", \"affects\" and \"affect\". \n",
    "To have a smaller size vocabulary and better representation on NLP problem, we want to have a single word to represent \"\", \"\" in some scenarios. In this article, we will go through some libraries to work on lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Capture from https://en.wikipedia.org/wiki/Lemmatisation\n",
    "\n",
    "article = \"Lemmatisation (or lemmatization) in linguistics is the process of grouping together \\\n",
    "the inflected forms of a word so they can be analysed as a single item, identified by the word's \\\n",
    "lemma, or dictionary form.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Version: 2.0.11\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print('spaCy Version: %s' % (spacy.__version__))\n",
    "spacy_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article: Lemmatisation (or lemmatization) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form.\n",
      "\n",
      "Original : Lemmatisation, New: lemmatisation\n",
      "Original : linguistics, New: linguistic\n",
      "Original : is, New: be\n",
      "Original : grouping, New: group\n",
      "Original : inflected, New: inflect\n",
      "Original : forms, New: form\n",
      "Original : they, New: -PRON-\n",
      "Original : analysed, New: analyse\n",
      "Original : identified, New: identify\n"
     ]
    }
   ],
   "source": [
    "doc = spacy_nlp(article)\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "print('Original Article: %s' % (article))\n",
    "print()\n",
    "\n",
    "for token in doc:\n",
    "    if token.text != token.lemma_:\n",
    "        print('Original : %s, New: %s' % (token.text, token.lemma_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy will convert word to lower case and changing past tense, gerund form (other tenses as well) to present tense. Also, \"they\" normalize to \"-PRON-\" which is pronoun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Version: 3.2.5\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "print('NLTK Version: %s' % (nltk.__version__))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article: Lemmatisation (or lemmatization) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form.\n",
      "\n",
      "Original : forms, New: form\n",
      "Original : as, New: a\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(article)\n",
    "\n",
    "print('Original Article: %s' % (article))\n",
    "print()\n",
    "\n",
    "for token in tokens:\n",
    "    lemmatized_token = wordnet_lemmatizer.lemmatize(token)\n",
    "    \n",
    "    if token != lemmatized_token:\n",
    "        print('Original : %s, New: %s' % (token, lemmatized_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is totally difference from spaCy. Only two words are lemmaizated and one of them \"as\" is strange. It seems that \"s\" will removed if it is the last character. Therefore, \"as\" is converted to \"a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of spaCy is better and expected. Taking \"as\" an example, it seems that spaCy\" has a kind of \"intelligent\" that it will convert \"as\" as \"a\". Therefore, I further studying on source code, it seems like there are well defined word and rule to support lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy from spacy/lang/en/lemmatizer/_lemma_rules.py\n",
    "ADJECTIVE_RULES = [\n",
    "    [\"er\", \"\"],\n",
    "    [\"est\", \"\"],\n",
    "    [\"er\", \"e\"],\n",
    "    [\"est\", \"e\"]\n",
    "]\n",
    "# Copy from spacy/lang/en/lemmatizer/_nouns_irreg.py\n",
    "NOUNS_IRREG = {\n",
    "    \"aardwolves\": (\"aardwolf\",),\n",
    "    \"abaci\": (\"abacus\",),\n",
    "    \"aboideaux\": (\"aboideau\",),\n",
    "    \"aboiteaux\": (\"aboiteau\",),\n",
    "    \"abscissae\": (\"abscissa\",),\n",
    "    \"acanthi\": (\"acanthus\",),\n",
    "    \"acari\": (\"acarus\",),\n",
    "#     ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy from spacy/lang/fr/lemmatizer.py\n",
    "LOOKUP = {\n",
    "    \"Ap.\": \"après\",\n",
    "    \"Apr.\": \"après\",\n",
    "    \"Auxerroises\": \"Auxerrois\",\n",
    "    \"Av.\": \"avenue\",\n",
    "    \"Ave.\": \"avenue\",\n",
    "    \"Avr.\": \"avril\",\n",
    "    \"Bd.\": \"boulevard\",\n",
    "    \"Boliviennes\": \"Bolivien\",\n",
    "    \"Canadiennes\": \"Canadien\",\n",
    "    \"Cannoises\": \"Cannois\",\n",
    "#     ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TL;DR\n",
    "\n",
    "How does spaCy work on lemmatizion in Enlgish. From source code, it will go through POS (Part of Speech) first. Lemmatization will be performed if the word is noun, verb, adjective or adverb. Later on, it will check whether existing in irregular list. Lemmatized word will be returned if existing in irregular list. Otherwise, it will go the pre-defined suffix rule."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
